{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from typing import Iterator, Optional\n",
    "import openai\n",
    "\n",
    "from llama_index.query_engine.retriever_query_engine import RetrieverQueryEngine\n",
    "from llama_index.callbacks.base import CallbackManager\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import chainlit as cl\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from llama_index.retrievers import VectorIndexRetriever\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "from llama_index.indices.postprocessor import SimilarityPostprocessor\n",
    "from llama_index.chat_engine.types import BaseChatEngine, ChatMode\n",
    "\n",
    "from llama_index import (\n",
    "    LLMPredictor,\n",
    "    ServiceContext,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    "    set_global_service_context,\n",
    ")\n",
    "from llama_index import (\n",
    "    VectorStoreIndex,\n",
    "    get_response_synthesizer,\n",
    ")\n",
    "\n",
    "from llama_index import GPTVectorStoreIndex, SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain gpt model name from environment variables\n",
    "gpt_model = \"gpt-4\"\n",
    "gpt_temperature = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_list = [\n",
    "\t'../quant_scraper/docs/vbt_pro/cookbook.md',\n",
    "\t# '../quant_scraper/docs/vbt_pro/documentation.md',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DefaultVectorStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_default_vector_storage():\n",
    "\t\tprint('Loading documents...')\n",
    "\t\tdocuments = SimpleDirectoryReader(input_files=document_list).load_data()\n",
    "\t\tprint('Building index...')\n",
    "\t\tindex = GPTVectorStoreIndex.from_documents(documents, show_progress=True)\n",
    "\n",
    "\t\tllm_predictor = LLMPredictor(\n",
    "\t\t\tllm=ChatOpenAI(\n",
    "\t\t\t\ttemperature=gpt_temperature,\n",
    "\t\t\t\tmodel_name=gpt_model,\n",
    "\t\t\t\tmax_tokens=2048,\n",
    "\t\t\t\tstreaming=True,\n",
    "\t\t\t),\n",
    "\t\t)\n",
    "\n",
    "\t\tservice_context = ServiceContext.from_defaults(\n",
    "\t\t\tllm_predictor=llm_predictor,\n",
    "\t\t\tchunk_size=1024,\n",
    "\t\t\tcallback_manager=CallbackManager([cl.LlamaIndexCallbackHandler()]),\n",
    "\t\t)\n",
    "\n",
    "\t\tretriever = VectorIndexRetriever(\n",
    "\t\t\tindex=index,\n",
    "\t\t\tsimilarity_top_k=10,\n",
    "\t\t)\n",
    "\t\t# configure response synthesizer\n",
    "\t\tresponse_synthesizer = get_response_synthesizer(\n",
    "\t\t\tresponse_mode=\"tree_summarize\", service_context=service_context)\n",
    "\n",
    "\t\t# assemble query engine\n",
    "\t\tquery_engine = RetrieverQueryEngine.from_args(\n",
    "\t\t\tstreaming=True,\n",
    "\t\t\tretriever=retriever,\n",
    "\t\t\tresponse_synthesizer=response_synthesizer,\n",
    "\t\t\tservice_context=service_context,\n",
    "\t\t\tnode_postprocessors=[\n",
    "\t\t\t\tSimilarityPostprocessor(similarity_cutoff=0.7)\n",
    "\t\t\t]\n",
    "\t\t)\n",
    "\n",
    "\t\treturn query_engine, index, service_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build default vector storage\n",
    "# query_engine_1, index_1, service_context_1 = build_default_vector_storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = \"\"\"\n",
    "In my strategy I have 4 take profits and stop loss. How can I move stop loss to breakeven after the first take profit is hit?\n",
    "\"\"\"\n",
    "\n",
    "# query_engine_1.query(test_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
